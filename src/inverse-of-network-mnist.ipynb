{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH = Path('../inputs')\n",
    "OUTPUT_PATH = Path('../outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Linear(in_features=500, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "torch.manual_seed(999)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        layer1 = self.get_linear_with_relu(input_size, 500)\n",
    "        layer2 = nn.Linear(500, out_size)\n",
    "        self.layers = nn.ModuleList([layer1, layer2])\n",
    "        self.forward_vals = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.forward_vals.clear()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            self.forward_vals.append(x)\n",
    "        return x\n",
    "    \n",
    "    def get_linear_with_relu(self, inp, out):\n",
    "        return nn.Sequential(nn.Linear(inp, out), nn.ReLU())\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "train_kwargs = {'batch_size': batch_size,\n",
    "               'shuffle': True}\n",
    "test_kwargs = {'batch_size': batch_size,\n",
    "              'shuffle': True}\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "dataset1 = datasets.MNIST(INPUT_PATH/'mnist', train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = datasets.MNIST(INPUT_PATH/'mnist', train=False,\n",
    "                   transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "model = Net(28*28, 10).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1e-2)\n",
    "            \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60032"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import copy\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# def train(model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         # print(data.size(), data.view(data.size(0), -1).size())\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data.view(data.size(0), -1))\n",
    "#         loss = F.cross_entropy(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "# def test():\n",
    "#     with torch.no_grad():\n",
    "#         n_correct = 0\n",
    "#         n_samples = 0\n",
    "#         for images, labels in test_loader:\n",
    "#             images = images.reshape(-1, 28*28).to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             # max returns (value ,index)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             n_samples += labels.size(0)\n",
    "#             n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     acc = 100.0 * n_correct / n_samples\n",
    "#     print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "#     return acc\n",
    "\n",
    "\n",
    "# best_acc = -1\n",
    "# best_model = None\n",
    "# for epoch in range(1, 120):\n",
    "#     train(model, device, train_loader, optimizer, epoch)\n",
    "#     acc = test()\n",
    "#     if acc > best_acc:\n",
    "#         best_acc = acc\n",
    "#         best_model = copy.deepcopy(model)\n",
    "#         print(f'new best acc={best_acc}')\n",
    "#     else:\n",
    "#         print(f'current acc={acc}, prev_best_acc={best_acc}')\n",
    "\n",
    "# state = {\n",
    "#     'model_state': best_model.state_dict(),\n",
    "#     'test_acc': best_acc\n",
    "# }\n",
    "# torch.save(state, OUTPUT_PATH/'state_small_nn.pt')\n",
    "# print('best model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_state', 'test_acc'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(OUTPUT_PATH/'state_small_nn.pt')\n",
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Linear(in_features=500, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state['model_state'])\n",
    "model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "                                 \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'epochs': 700,\n",
    "    'alpha': 1,\n",
    "    'lr': 1e-2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of inv data=Dataset QMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../inputs/qmnist\n",
      "    Split: test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InvNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=500, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Linear(in_features=500, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class InvNet(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super(InvNet, self).__init__()\n",
    "        layer1 = self.get_linear_with_relu(input_size, 500)\n",
    "        layer2 = nn.Linear(500, out_size)\n",
    "        self.layers = nn.ModuleList([layer1, layer2])\n",
    "        self.forward_vals = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.forward_vals.clear()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            self.forward_vals.append(x)\n",
    "        return x\n",
    "    \n",
    "    def get_linear_with_relu(self, inp, out):\n",
    "        return nn.Sequential(nn.Linear(inp, out), nn.ReLU())\n",
    "    \n",
    "inv_model = InvNet(10, 28*28)\n",
    "inv_model.to(device)\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "test_kwargs = {'batch_size': batch_size,\n",
    "              'shuffle': True}\n",
    "test_qmnist = datasets.QMNIST(INPUT_PATH/'qmnist', train = False, download= True,\n",
    "                             transform=transform)\n",
    "print(f'size of inv data={test_qmnist}')\n",
    "inv_data_loader = torch.utils.data.DataLoader(test_qmnist, **test_kwargs)\n",
    "\n",
    "optimizer = optim.Adam(inv_model.parameters(), lr=config_dict['lr'])\n",
    "\n",
    "inv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "for i in range(6):\n",
    "    example_data, example_target = test_qmnist[random.randint(0, len(test_qmnist))]\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "tgt_to_inv_layer_map = {0: 1, 1: 0}\n",
    "\n",
    "def train_inv(model, inv_model, device, data_loader, optimizer, epoch, alpha):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_loss_layer = 0\n",
    "    total_loss_img = 0\n",
    "    total_loss_cyc = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device).view(data.size(0), -1), target.to(device)  # torch.Size([128, 784]) torch.Size([128])\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        out = model(data)  \n",
    "        inv_out = inv_model(out)\n",
    "        \n",
    "        # step 1- layer wise load\n",
    "        loss_layer = layer_wise_loss(model, inv_model, data)\n",
    "        \n",
    "        # step 2- upto layer-k loss\n",
    "        loss_img = F.l1_loss(inv_out, data)\n",
    "        \n",
    "        # step 3- full network output loss\n",
    "        loss_cyc = cycle_consistency_inversion_loss(model, data, inv_out)\n",
    "        \n",
    "        loss = loss_layer + loss_img + (alpha*loss_cyc)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_loss_layer += loss_layer.item()\n",
    "        total_loss_img += loss_img.item()\n",
    "        total_loss_cyc += loss_cyc.item()\n",
    "        \n",
    "    return total_loss / (batch_idx+1), total_loss_layer / (batch_idx+1), \\\n",
    "            total_loss_img / (batch_idx+1), total_loss_cyc / (batch_idx+1)\n",
    "        \n",
    "        \n",
    "\n",
    "def layer_wise_loss(model, inv_model, inp):\n",
    "    loss = 0\n",
    "    for layer_num, layer in enumerate(model.layers):\n",
    "        tgt_layer_in = inp if layer_num == 0 else model.forward_vals[layer_num-1]  # get the input tensor for this layer in tgt model\n",
    "        tgt_layer_out = model.forward_vals[layer_num]  # get the output of i-th target model layer \n",
    "        inv_layer = inv_model.layers[tgt_to_inv_layer_map[layer_num]]  # get the corresponding layer in reverse model\n",
    "        inv_layer_out = inv_layer(tgt_layer_out)  # feed the target model layer output to reverse model layer\n",
    "        loss += F.l1_loss(inv_layer_out, tgt_layer_in)  # outputs of both layer should be similar\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "def cycle_consistency_inversion_loss(model, inp, inv_out):\n",
    "    org_activations = copy.deepcopy(model.forward_vals)\n",
    "    out_for_inv_input = model(inv_out)  # pass the input image generated by inverted network\n",
    "    loss = 0\n",
    "    for org_actv, actv in zip(org_activations, model.forward_vals):\n",
    "        loss += F.l1_loss(actv, org_actv)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">lr_1e-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nayash/nn-are-reversible\" target=\"_blank\">https://wandb.ai/nayash/nn-are-reversible</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nayash/nn-are-reversible/runs/lr_1e-2\" target=\"_blank\">https://wandb.ai/nayash/nn-are-reversible/runs/lr_1e-2</a><br/>\n",
       "                Run data is saved locally in <code>../outputs/runs/lr_1e-2/wandb/run-20211024_004119-lr_1e-2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/700 loss=1.51335, loss_layer=0.75188, loss_img=0.30314, loss_cyc=0.45832, epoch_duration=8 secs\n",
      "new best loss=1.5133456345051846\n",
      "epoch=1/700 loss=1.51316, loss_layer=0.75172, loss_img=0.30314, loss_cyc=0.4583, epoch_duration=8 secs\n",
      "new best loss=1.513158120834497\n",
      "epoch=2/700 loss=1.5148, loss_layer=0.75191, loss_img=0.30313, loss_cyc=0.45976, epoch_duration=8 secs\n",
      "epoch=3/700 loss=1.51178, loss_layer=0.75148, loss_img=0.303, loss_cyc=0.45729, epoch_duration=8 secs\n",
      "new best loss=1.5117752668954163\n",
      "epoch=4/700 loss=1.51345, loss_layer=0.75166, loss_img=0.30312, loss_cyc=0.45867, epoch_duration=8 secs\n",
      "epoch=5/700 loss=1.51106, loss_layer=0.75147, loss_img=0.3031, loss_cyc=0.45649, epoch_duration=9 secs\n",
      "new best loss=1.5110565251124692\n",
      "epoch=6/700 loss=1.51513, loss_layer=0.75168, loss_img=0.3032, loss_cyc=0.46024, epoch_duration=8 secs\n",
      "epoch=7/700 loss=1.51222, loss_layer=0.75148, loss_img=0.30305, loss_cyc=0.4577, epoch_duration=8 secs\n",
      "epoch=8/700 loss=1.51305, loss_layer=0.75151, loss_img=0.30307, loss_cyc=0.45847, epoch_duration=8 secs\n",
      "epoch=9/700 loss=1.51332, loss_layer=0.75143, loss_img=0.30307, loss_cyc=0.45882, epoch_duration=8 secs\n",
      "epoch=10/700 loss=1.51422, loss_layer=0.75138, loss_img=0.30305, loss_cyc=0.45979, epoch_duration=8 secs\n",
      "epoch=11/700 loss=1.50976, loss_layer=0.75121, loss_img=0.30298, loss_cyc=0.45557, epoch_duration=8 secs\n",
      "new best loss=1.5097585837724112\n",
      "epoch=12/700 loss=1.51505, loss_layer=0.7516, loss_img=0.30314, loss_cyc=0.46031, epoch_duration=8 secs\n",
      "epoch=13/700 loss=1.5108, loss_layer=0.75113, loss_img=0.30299, loss_cyc=0.45668, epoch_duration=9 secs\n",
      "epoch=14/700 loss=1.51238, loss_layer=0.75129, loss_img=0.30308, loss_cyc=0.45801, epoch_duration=9 secs\n",
      "epoch=15/700 loss=1.51277, loss_layer=0.75128, loss_img=0.30305, loss_cyc=0.45844, epoch_duration=9 secs\n",
      "epoch=16/700 loss=1.51349, loss_layer=0.75126, loss_img=0.30308, loss_cyc=0.45915, epoch_duration=9 secs\n",
      "epoch=17/700 loss=1.51569, loss_layer=0.75131, loss_img=0.30307, loss_cyc=0.46131, epoch_duration=9 secs\n",
      "epoch=18/700 loss=1.51145, loss_layer=0.75109, loss_img=0.30295, loss_cyc=0.45741, epoch_duration=9 secs\n",
      "epoch=19/700 loss=1.50976, loss_layer=0.75087, loss_img=0.30294, loss_cyc=0.45596, epoch_duration=9 secs\n",
      "epoch=20/700 loss=1.51151, loss_layer=0.75109, loss_img=0.30301, loss_cyc=0.45742, epoch_duration=9 secs\n",
      "epoch=21/700 loss=1.51275, loss_layer=0.75116, loss_img=0.30311, loss_cyc=0.45848, epoch_duration=9 secs\n",
      "epoch=22/700 loss=1.5123, loss_layer=0.75104, loss_img=0.30299, loss_cyc=0.45827, epoch_duration=8 secs\n",
      "epoch=23/700 loss=1.51187, loss_layer=0.75105, loss_img=0.30304, loss_cyc=0.45778, epoch_duration=8 secs\n",
      "epoch=24/700 loss=1.51149, loss_layer=0.75093, loss_img=0.30302, loss_cyc=0.45754, epoch_duration=8 secs\n",
      "epoch=25/700 loss=1.51391, loss_layer=0.75109, loss_img=0.30311, loss_cyc=0.45971, epoch_duration=8 secs\n",
      "epoch=26/700 loss=1.51026, loss_layer=0.75074, loss_img=0.30293, loss_cyc=0.45659, epoch_duration=8 secs\n",
      "epoch=27/700 loss=1.51216, loss_layer=0.75094, loss_img=0.30299, loss_cyc=0.45823, epoch_duration=8 secs\n",
      "epoch=28/700 loss=1.51222, loss_layer=0.75088, loss_img=0.30297, loss_cyc=0.45837, epoch_duration=8 secs\n",
      "epoch=29/700 loss=1.5116, loss_layer=0.7508, loss_img=0.30296, loss_cyc=0.45784, epoch_duration=8 secs\n",
      "epoch=30/700 loss=1.51054, loss_layer=0.75076, loss_img=0.30296, loss_cyc=0.45682, epoch_duration=8 secs\n",
      "epoch=31/700 loss=1.51131, loss_layer=0.75072, loss_img=0.30299, loss_cyc=0.4576, epoch_duration=8 secs\n",
      "epoch=32/700 loss=1.51229, loss_layer=0.75084, loss_img=0.30299, loss_cyc=0.45846, epoch_duration=8 secs\n",
      "epoch=33/700 loss=1.5101, loss_layer=0.75067, loss_img=0.30297, loss_cyc=0.45646, epoch_duration=8 secs\n",
      "epoch=34/700 loss=1.51447, loss_layer=0.75081, loss_img=0.30305, loss_cyc=0.46061, epoch_duration=8 secs\n",
      "epoch=35/700 loss=1.51246, loss_layer=0.75066, loss_img=0.30293, loss_cyc=0.45887, epoch_duration=8 secs\n",
      "epoch=36/700 loss=1.51213, loss_layer=0.75071, loss_img=0.30296, loss_cyc=0.45846, epoch_duration=8 secs\n",
      "epoch=37/700 loss=1.50881, loss_layer=0.75036, loss_img=0.30285, loss_cyc=0.4556, epoch_duration=8 secs\n",
      "new best loss=1.5088078358025947\n",
      "epoch=38/700 loss=1.51314, loss_layer=0.75066, loss_img=0.30298, loss_cyc=0.4595, epoch_duration=9 secs\n",
      "epoch=39/700 loss=1.51084, loss_layer=0.75048, loss_img=0.3029, loss_cyc=0.45745, epoch_duration=9 secs\n",
      "epoch=40/700 loss=1.51429, loss_layer=0.75062, loss_img=0.30298, loss_cyc=0.4607, epoch_duration=9 secs\n",
      "epoch=41/700 loss=1.51092, loss_layer=0.75038, loss_img=0.30285, loss_cyc=0.4577, epoch_duration=8 secs\n",
      "epoch=42/700 loss=1.50909, loss_layer=0.75031, loss_img=0.30285, loss_cyc=0.45593, epoch_duration=8 secs\n",
      "epoch=43/700 loss=1.51011, loss_layer=0.75032, loss_img=0.30292, loss_cyc=0.45687, epoch_duration=9 secs\n",
      "epoch=44/700 loss=1.51071, loss_layer=0.75032, loss_img=0.30296, loss_cyc=0.45742, epoch_duration=8 secs\n",
      "epoch=45/700 loss=1.51456, loss_layer=0.75053, loss_img=0.30299, loss_cyc=0.46104, epoch_duration=8 secs\n",
      "epoch=46/700 loss=1.5104, loss_layer=0.75022, loss_img=0.3029, loss_cyc=0.45728, epoch_duration=8 secs\n",
      "epoch=47/700 loss=1.51089, loss_layer=0.75028, loss_img=0.30291, loss_cyc=0.4577, epoch_duration=9 secs\n",
      "epoch=48/700 loss=1.51083, loss_layer=0.75021, loss_img=0.30288, loss_cyc=0.45775, epoch_duration=8 secs\n",
      "epoch=49/700 loss=1.50963, loss_layer=0.75013, loss_img=0.3029, loss_cyc=0.45661, epoch_duration=8 secs\n",
      "epoch=50/700 loss=1.51133, loss_layer=0.75027, loss_img=0.30297, loss_cyc=0.45809, epoch_duration=8 secs\n",
      "epoch=51/700 loss=1.50998, loss_layer=0.75004, loss_img=0.30289, loss_cyc=0.45705, epoch_duration=8 secs\n",
      "epoch=52/700 loss=1.51445, loss_layer=0.75029, loss_img=0.30299, loss_cyc=0.46117, epoch_duration=8 secs\n",
      "epoch=53/700 loss=1.50987, loss_layer=0.75007, loss_img=0.30284, loss_cyc=0.45696, epoch_duration=8 secs\n",
      "epoch=54/700 loss=1.5112, loss_layer=0.7501, loss_img=0.30288, loss_cyc=0.45823, epoch_duration=8 secs\n",
      "epoch=55/700 loss=1.51078, loss_layer=0.75008, loss_img=0.30288, loss_cyc=0.45782, epoch_duration=8 secs\n",
      "epoch=56/700 loss=1.50824, loss_layer=0.74978, loss_img=0.30279, loss_cyc=0.45566, epoch_duration=8 secs\n",
      "new best loss=1.5082401210056948\n",
      "epoch=57/700 loss=1.51169, loss_layer=0.74998, loss_img=0.30287, loss_cyc=0.45884, epoch_duration=8 secs\n",
      "epoch=58/700 loss=1.51069, loss_layer=0.75001, loss_img=0.30286, loss_cyc=0.45782, epoch_duration=9 secs\n",
      "epoch=59/700 loss=1.5086, loss_layer=0.74975, loss_img=0.30278, loss_cyc=0.45607, epoch_duration=8 secs\n",
      "epoch=60/700 loss=1.5093, loss_layer=0.74979, loss_img=0.30285, loss_cyc=0.45666, epoch_duration=8 secs\n",
      "epoch=61/700 loss=1.50885, loss_layer=0.7498, loss_img=0.30288, loss_cyc=0.45617, epoch_duration=8 secs\n",
      "epoch=62/700 loss=1.51414, loss_layer=0.75016, loss_img=0.30299, loss_cyc=0.46098, epoch_duration=8 secs\n",
      "epoch=63/700 loss=1.51161, loss_layer=0.74992, loss_img=0.30282, loss_cyc=0.45887, epoch_duration=8 secs\n",
      "epoch=64/700 loss=1.51011, loss_layer=0.74977, loss_img=0.30283, loss_cyc=0.45751, epoch_duration=8 secs\n",
      "epoch=65/700 loss=1.50996, loss_layer=0.74975, loss_img=0.30282, loss_cyc=0.45739, epoch_duration=9 secs\n",
      "epoch=66/700 loss=1.51128, loss_layer=0.74983, loss_img=0.30286, loss_cyc=0.4586, epoch_duration=8 secs\n",
      "epoch=67/700 loss=1.51074, loss_layer=0.7498, loss_img=0.3028, loss_cyc=0.45814, epoch_duration=8 secs\n",
      "epoch=68/700 loss=1.51093, loss_layer=0.74973, loss_img=0.30287, loss_cyc=0.45833, epoch_duration=8 secs\n",
      "epoch=69/700 loss=1.51133, loss_layer=0.74971, loss_img=0.30275, loss_cyc=0.45887, epoch_duration=8 secs\n",
      "epoch=70/700 loss=1.51038, loss_layer=0.74953, loss_img=0.30274, loss_cyc=0.45811, epoch_duration=8 secs\n",
      "epoch=71/700 loss=1.50988, loss_layer=0.74962, loss_img=0.30276, loss_cyc=0.4575, epoch_duration=8 secs\n",
      "epoch=72/700 loss=1.50996, loss_layer=0.74963, loss_img=0.30281, loss_cyc=0.45752, epoch_duration=9 secs\n",
      "epoch=73/700 loss=1.50881, loss_layer=0.74949, loss_img=0.30275, loss_cyc=0.45656, epoch_duration=8 secs\n",
      "epoch=74/700 loss=1.51108, loss_layer=0.74966, loss_img=0.30283, loss_cyc=0.4586, epoch_duration=8 secs\n",
      "epoch=75/700 loss=1.51104, loss_layer=0.7496, loss_img=0.30284, loss_cyc=0.4586, epoch_duration=8 secs\n",
      "epoch=76/700 loss=1.51047, loss_layer=0.74954, loss_img=0.30279, loss_cyc=0.45814, epoch_duration=8 secs\n",
      "epoch=77/700 loss=1.51019, loss_layer=0.74957, loss_img=0.30278, loss_cyc=0.45784, epoch_duration=8 secs\n",
      "epoch=78/700 loss=1.51126, loss_layer=0.74947, loss_img=0.30277, loss_cyc=0.45901, epoch_duration=8 secs\n",
      "epoch=79/700 loss=1.50951, loss_layer=0.74945, loss_img=0.30275, loss_cyc=0.4573, epoch_duration=8 secs\n",
      "epoch=80/700 loss=1.50734, loss_layer=0.74918, loss_img=0.3027, loss_cyc=0.45547, epoch_duration=8 secs\n",
      "new best loss=1.5073426733138973\n",
      "epoch=81/700 loss=1.51166, loss_layer=0.74959, loss_img=0.30286, loss_cyc=0.45922, epoch_duration=8 secs\n",
      "epoch=82/700 loss=1.50879, loss_layer=0.7493, loss_img=0.30276, loss_cyc=0.45673, epoch_duration=8 secs\n",
      "epoch=83/700 loss=1.51405, loss_layer=0.74956, loss_img=0.30285, loss_cyc=0.46165, epoch_duration=8 secs\n",
      "epoch=84/700 loss=1.50915, loss_layer=0.74922, loss_img=0.3027, loss_cyc=0.45723, epoch_duration=8 secs\n",
      "epoch=85/700 loss=1.50837, loss_layer=0.74914, loss_img=0.30266, loss_cyc=0.45656, epoch_duration=8 secs\n",
      "epoch=86/700 loss=1.51105, loss_layer=0.74942, loss_img=0.30278, loss_cyc=0.45885, epoch_duration=8 secs\n",
      "epoch=87/700 loss=1.50885, loss_layer=0.74921, loss_img=0.30273, loss_cyc=0.45691, epoch_duration=9 secs\n",
      "epoch=88/700 loss=1.50834, loss_layer=0.74915, loss_img=0.30272, loss_cyc=0.45647, epoch_duration=8 secs\n",
      "epoch=89/700 loss=1.50845, loss_layer=0.74919, loss_img=0.30274, loss_cyc=0.45652, epoch_duration=8 secs\n",
      "epoch=90/700 loss=1.50907, loss_layer=0.74922, loss_img=0.30277, loss_cyc=0.45708, epoch_duration=8 secs\n",
      "epoch=91/700 loss=1.51011, loss_layer=0.74928, loss_img=0.30277, loss_cyc=0.45806, epoch_duration=9 secs\n",
      "epoch=92/700 loss=1.51183, loss_layer=0.74934, loss_img=0.30278, loss_cyc=0.45971, epoch_duration=8 secs\n",
      "epoch=93/700 loss=1.50705, loss_layer=0.74901, loss_img=0.3027, loss_cyc=0.45535, epoch_duration=8 secs\n",
      "new best loss=1.5070521432453636\n",
      "epoch=94/700 loss=1.51278, loss_layer=0.74937, loss_img=0.30283, loss_cyc=0.46059, epoch_duration=8 secs\n",
      "epoch=95/700 loss=1.51069, loss_layer=0.74911, loss_img=0.30262, loss_cyc=0.45896, epoch_duration=8 secs\n",
      "epoch=96/700 loss=1.50952, loss_layer=0.74903, loss_img=0.30262, loss_cyc=0.45787, epoch_duration=8 secs\n",
      "epoch=97/700 loss=1.51006, loss_layer=0.74911, loss_img=0.30269, loss_cyc=0.45825, epoch_duration=8 secs\n",
      "epoch=98/700 loss=1.50746, loss_layer=0.74886, loss_img=0.30265, loss_cyc=0.45595, epoch_duration=8 secs\n",
      "epoch=99/700 loss=1.50798, loss_layer=0.74891, loss_img=0.30266, loss_cyc=0.4564, epoch_duration=8 secs\n",
      "epoch=100/700 loss=1.50825, loss_layer=0.7489, loss_img=0.30269, loss_cyc=0.45665, epoch_duration=8 secs\n",
      "epoch=101/700 loss=1.51113, loss_layer=0.74917, loss_img=0.3028, loss_cyc=0.45916, epoch_duration=8 secs\n",
      "epoch=102/700 loss=1.51038, loss_layer=0.749, loss_img=0.30268, loss_cyc=0.4587, epoch_duration=8 secs\n",
      "epoch=103/700 loss=1.51124, loss_layer=0.74923, loss_img=0.30277, loss_cyc=0.45924, epoch_duration=8 secs\n",
      "epoch=104/700 loss=1.50895, loss_layer=0.74888, loss_img=0.30263, loss_cyc=0.45744, epoch_duration=8 secs\n",
      "epoch=105/700 loss=1.50842, loss_layer=0.74882, loss_img=0.30266, loss_cyc=0.45694, epoch_duration=8 secs\n",
      "epoch=106/700 loss=1.50882, loss_layer=0.74887, loss_img=0.30269, loss_cyc=0.45726, epoch_duration=8 secs\n",
      "epoch=107/700 loss=1.50793, loss_layer=0.74879, loss_img=0.30266, loss_cyc=0.45648, epoch_duration=8 secs\n",
      "epoch=108/700 loss=1.50916, loss_layer=0.74886, loss_img=0.30267, loss_cyc=0.45762, epoch_duration=8 secs\n",
      "epoch=109/700 loss=1.51012, loss_layer=0.74881, loss_img=0.30269, loss_cyc=0.45862, epoch_duration=8 secs\n",
      "epoch=110/700 loss=1.51012, loss_layer=0.74879, loss_img=0.30264, loss_cyc=0.45868, epoch_duration=8 secs\n",
      "epoch=111/700 loss=1.509, loss_layer=0.74866, loss_img=0.3026, loss_cyc=0.45774, epoch_duration=8 secs\n",
      "epoch=112/700 loss=1.50889, loss_layer=0.74871, loss_img=0.3026, loss_cyc=0.45758, epoch_duration=8 secs\n",
      "epoch=113/700 loss=1.5092, loss_layer=0.74864, loss_img=0.30267, loss_cyc=0.45789, epoch_duration=8 secs\n",
      "epoch=114/700 loss=1.5077, loss_layer=0.74867, loss_img=0.30263, loss_cyc=0.4564, epoch_duration=8 secs\n",
      "epoch=115/700 loss=1.5106, loss_layer=0.74886, loss_img=0.3027, loss_cyc=0.45903, epoch_duration=8 secs\n",
      "epoch=116/700 loss=1.50891, loss_layer=0.7486, loss_img=0.30262, loss_cyc=0.45769, epoch_duration=8 secs\n",
      "epoch=117/700 loss=1.50721, loss_layer=0.74853, loss_img=0.30264, loss_cyc=0.45604, epoch_duration=8 secs\n",
      "epoch=118/700 loss=1.50882, loss_layer=0.74864, loss_img=0.30268, loss_cyc=0.4575, epoch_duration=8 secs\n",
      "epoch=119/700 loss=1.50906, loss_layer=0.74859, loss_img=0.30261, loss_cyc=0.45786, epoch_duration=9 secs\n",
      "epoch=120/700 loss=1.50912, loss_layer=0.7486, loss_img=0.30263, loss_cyc=0.45789, epoch_duration=8 secs\n",
      "epoch=121/700 loss=1.51008, loss_layer=0.74865, loss_img=0.30264, loss_cyc=0.45879, epoch_duration=8 secs\n",
      "epoch=122/700 loss=1.51043, loss_layer=0.74853, loss_img=0.30257, loss_cyc=0.45933, epoch_duration=8 secs\n",
      "epoch=123/700 loss=1.50801, loss_layer=0.74842, loss_img=0.30259, loss_cyc=0.457, epoch_duration=8 secs\n",
      "epoch=124/700 loss=1.50673, loss_layer=0.74837, loss_img=0.30256, loss_cyc=0.45581, epoch_duration=8 secs\n",
      "new best loss=1.506729207313391\n",
      "epoch=125/700 loss=1.5095, loss_layer=0.74852, loss_img=0.30263, loss_cyc=0.45835, epoch_duration=8 secs\n",
      "epoch=126/700 loss=1.5082, loss_layer=0.74848, loss_img=0.30259, loss_cyc=0.45713, epoch_duration=8 secs\n",
      "epoch=127/700 loss=1.50836, loss_layer=0.74843, loss_img=0.30259, loss_cyc=0.45734, epoch_duration=8 secs\n",
      "epoch=128/700 loss=1.50734, loss_layer=0.74841, loss_img=0.30262, loss_cyc=0.45631, epoch_duration=9 secs\n",
      "epoch=129/700 loss=1.50781, loss_layer=0.74839, loss_img=0.30257, loss_cyc=0.45685, epoch_duration=9 secs\n",
      "epoch=130/700 loss=1.51143, loss_layer=0.74859, loss_img=0.30267, loss_cyc=0.46017, epoch_duration=8 secs\n",
      "epoch=131/700 loss=1.5076, loss_layer=0.74832, loss_img=0.30255, loss_cyc=0.45673, epoch_duration=8 secs\n",
      "epoch=132/700 loss=1.50853, loss_layer=0.74839, loss_img=0.3026, loss_cyc=0.45754, epoch_duration=8 secs\n",
      "epoch=133/700 loss=1.50673, loss_layer=0.74827, loss_img=0.30255, loss_cyc=0.45591, epoch_duration=8 secs\n",
      "epoch=134/700 loss=1.51066, loss_layer=0.74849, loss_img=0.30266, loss_cyc=0.4595, epoch_duration=8 secs\n",
      "epoch=135/700 loss=1.5106, loss_layer=0.74852, loss_img=0.30258, loss_cyc=0.45949, epoch_duration=8 secs\n",
      "epoch=136/700 loss=1.50679, loss_layer=0.74819, loss_img=0.30252, loss_cyc=0.45607, epoch_duration=8 secs\n",
      "epoch=137/700 loss=1.50933, loss_layer=0.74833, loss_img=0.30262, loss_cyc=0.45837, epoch_duration=8 secs\n",
      "epoch=138/700 loss=1.50834, loss_layer=0.74823, loss_img=0.3025, loss_cyc=0.45761, epoch_duration=8 secs\n",
      "epoch=139/700 loss=1.50714, loss_layer=0.74821, loss_img=0.30255, loss_cyc=0.45637, epoch_duration=8 secs\n",
      "epoch=140/700 loss=1.50874, loss_layer=0.74808, loss_img=0.30247, loss_cyc=0.4582, epoch_duration=8 secs\n",
      "epoch=141/700 loss=1.51126, loss_layer=0.74835, loss_img=0.30256, loss_cyc=0.46035, epoch_duration=9 secs\n",
      "epoch=142/700 loss=1.50601, loss_layer=0.74804, loss_img=0.30242, loss_cyc=0.45556, epoch_duration=8 secs\n",
      "new best loss=1.506010507723924\n",
      "epoch=143/700 loss=1.50683, loss_layer=0.748, loss_img=0.30253, loss_cyc=0.45629, epoch_duration=8 secs\n",
      "epoch=144/700 loss=1.50715, loss_layer=0.74811, loss_img=0.30255, loss_cyc=0.45649, epoch_duration=9 secs\n",
      "epoch=145/700 loss=1.50906, loss_layer=0.74817, loss_img=0.30254, loss_cyc=0.45834, epoch_duration=8 secs\n",
      "epoch=146/700 loss=1.50915, loss_layer=0.74811, loss_img=0.30256, loss_cyc=0.45848, epoch_duration=8 secs\n",
      "epoch=147/700 loss=1.50997, loss_layer=0.74826, loss_img=0.30262, loss_cyc=0.45909, epoch_duration=8 secs\n",
      "epoch=148/700 loss=1.50858, loss_layer=0.74807, loss_img=0.3025, loss_cyc=0.45802, epoch_duration=8 secs\n",
      "epoch=149/700 loss=1.50806, loss_layer=0.748, loss_img=0.30254, loss_cyc=0.45752, epoch_duration=8 secs\n",
      "epoch=150/700 loss=1.50796, loss_layer=0.74811, loss_img=0.30251, loss_cyc=0.45734, epoch_duration=8 secs\n",
      "epoch=151/700 loss=1.50876, loss_layer=0.74814, loss_img=0.30251, loss_cyc=0.45811, epoch_duration=8 secs\n",
      "epoch=152/700 loss=1.50689, loss_layer=0.74793, loss_img=0.30247, loss_cyc=0.45649, epoch_duration=8 secs\n",
      "epoch=153/700 loss=1.51068, loss_layer=0.74804, loss_img=0.30247, loss_cyc=0.46017, epoch_duration=8 secs\n",
      "epoch=154/700 loss=1.50774, loss_layer=0.74799, loss_img=0.30247, loss_cyc=0.45728, epoch_duration=8 secs\n",
      "epoch=155/700 loss=1.50595, loss_layer=0.74781, loss_img=0.30243, loss_cyc=0.45571, epoch_duration=8 secs\n",
      "new best loss=1.505952003668112\n",
      "epoch=156/700 loss=1.50694, loss_layer=0.74781, loss_img=0.30245, loss_cyc=0.45668, epoch_duration=8 secs\n",
      "epoch=157/700 loss=1.5114, loss_layer=0.74811, loss_img=0.30257, loss_cyc=0.46072, epoch_duration=8 secs\n",
      "epoch=158/700 loss=1.50722, loss_layer=0.74775, loss_img=0.30242, loss_cyc=0.45706, epoch_duration=8 secs\n",
      "epoch=159/700 loss=1.50649, loss_layer=0.74781, loss_img=0.30245, loss_cyc=0.45624, epoch_duration=8 secs\n",
      "epoch=160/700 loss=1.50656, loss_layer=0.74778, loss_img=0.30244, loss_cyc=0.45634, epoch_duration=8 secs\n",
      "epoch=161/700 loss=1.50799, loss_layer=0.74788, loss_img=0.30251, loss_cyc=0.4576, epoch_duration=8 secs\n",
      "epoch=162/700 loss=1.51397, loss_layer=0.74814, loss_img=0.30258, loss_cyc=0.46326, epoch_duration=8 secs\n",
      "epoch=163/700 loss=1.50408, loss_layer=0.7476, loss_img=0.30237, loss_cyc=0.45411, epoch_duration=8 secs\n",
      "new best loss=1.5040766257467046\n",
      "epoch=164/700 loss=1.50752, loss_layer=0.74776, loss_img=0.30249, loss_cyc=0.45727, epoch_duration=8 secs\n",
      "epoch=165/700 loss=1.51087, loss_layer=0.74792, loss_img=0.3025, loss_cyc=0.46045, epoch_duration=8 secs\n",
      "epoch=166/700 loss=1.50711, loss_layer=0.7477, loss_img=0.30245, loss_cyc=0.45696, epoch_duration=8 secs\n",
      "epoch=167/700 loss=1.50926, loss_layer=0.74788, loss_img=0.30255, loss_cyc=0.45883, epoch_duration=8 secs\n",
      "epoch=168/700 loss=1.50562, loss_layer=0.74759, loss_img=0.30243, loss_cyc=0.4556, epoch_duration=8 secs\n",
      "epoch=169/700 loss=1.50943, loss_layer=0.74787, loss_img=0.30247, loss_cyc=0.45909, epoch_duration=8 secs\n",
      "epoch=170/700 loss=1.50703, loss_layer=0.74758, loss_img=0.30241, loss_cyc=0.45704, epoch_duration=9 secs\n",
      "epoch=171/700 loss=1.50979, loss_layer=0.74789, loss_img=0.30254, loss_cyc=0.45937, epoch_duration=9 secs\n",
      "epoch=172/700 loss=1.50653, loss_layer=0.74756, loss_img=0.30242, loss_cyc=0.45656, epoch_duration=9 secs\n",
      "epoch=173/700 loss=1.50669, loss_layer=0.74756, loss_img=0.30243, loss_cyc=0.4567, epoch_duration=8 secs\n",
      "epoch=174/700 loss=1.50577, loss_layer=0.74745, loss_img=0.3024, loss_cyc=0.45592, epoch_duration=8 secs\n",
      "epoch=175/700 loss=1.50977, loss_layer=0.74772, loss_img=0.30249, loss_cyc=0.45955, epoch_duration=8 secs\n",
      "epoch=176/700 loss=1.50771, loss_layer=0.74745, loss_img=0.30243, loss_cyc=0.45782, epoch_duration=8 secs\n",
      "epoch=177/700 loss=1.5064, loss_layer=0.74747, loss_img=0.30237, loss_cyc=0.45656, epoch_duration=8 secs\n",
      "epoch=178/700 loss=1.5088, loss_layer=0.74763, loss_img=0.30245, loss_cyc=0.45873, epoch_duration=8 secs\n",
      "epoch=179/700 loss=1.50883, loss_layer=0.74771, loss_img=0.30244, loss_cyc=0.45867, epoch_duration=9 secs\n",
      "epoch=180/700 loss=1.5091, loss_layer=0.74754, loss_img=0.30244, loss_cyc=0.45912, epoch_duration=8 secs\n",
      "epoch=181/700 loss=1.50863, loss_layer=0.7476, loss_img=0.30239, loss_cyc=0.45864, epoch_duration=8 secs\n",
      "epoch=182/700 loss=1.50848, loss_layer=0.74754, loss_img=0.30239, loss_cyc=0.45854, epoch_duration=8 secs\n",
      "epoch=183/700 loss=1.50469, loss_layer=0.74724, loss_img=0.30233, loss_cyc=0.45512, epoch_duration=8 secs\n",
      "epoch=184/700 loss=1.50928, loss_layer=0.74755, loss_img=0.30241, loss_cyc=0.45932, epoch_duration=8 secs\n",
      "epoch=185/700 loss=1.50414, loss_layer=0.74725, loss_img=0.3023, loss_cyc=0.45458, epoch_duration=8 secs\n",
      "epoch=186/700 loss=1.50601, loss_layer=0.74727, loss_img=0.30236, loss_cyc=0.45638, epoch_duration=8 secs\n",
      "epoch=187/700 loss=1.50818, loss_layer=0.7475, loss_img=0.30243, loss_cyc=0.45825, epoch_duration=8 secs\n",
      "epoch=188/700 loss=1.50844, loss_layer=0.74744, loss_img=0.30241, loss_cyc=0.4586, epoch_duration=8 secs\n",
      "epoch=189/700 loss=1.50517, loss_layer=0.74729, loss_img=0.30234, loss_cyc=0.45554, epoch_duration=8 secs\n",
      "epoch=190/700 loss=1.50761, loss_layer=0.74733, loss_img=0.30238, loss_cyc=0.45789, epoch_duration=8 secs\n",
      "epoch=191/700 loss=1.50536, loss_layer=0.74725, loss_img=0.30237, loss_cyc=0.45575, epoch_duration=8 secs\n",
      "epoch=192/700 loss=1.5099, loss_layer=0.74752, loss_img=0.30249, loss_cyc=0.45989, epoch_duration=9 secs\n",
      "epoch=193/700 loss=1.50458, loss_layer=0.74713, loss_img=0.30229, loss_cyc=0.45516, epoch_duration=10 secs\n",
      "epoch=194/700 loss=1.50887, loss_layer=0.74732, loss_img=0.30242, loss_cyc=0.45913, epoch_duration=8 secs\n",
      "epoch=195/700 loss=1.50714, loss_layer=0.74731, loss_img=0.30237, loss_cyc=0.45746, epoch_duration=9 secs\n",
      "epoch=196/700 loss=1.50707, loss_layer=0.74719, loss_img=0.30234, loss_cyc=0.45754, epoch_duration=8 secs\n",
      "epoch=197/700 loss=1.50831, loss_layer=0.74734, loss_img=0.30243, loss_cyc=0.45854, epoch_duration=9 secs\n",
      "epoch=198/700 loss=1.5101, loss_layer=0.74736, loss_img=0.30235, loss_cyc=0.46039, epoch_duration=9 secs\n",
      "epoch=199/700 loss=1.50777, loss_layer=0.7472, loss_img=0.30232, loss_cyc=0.45824, epoch_duration=9 secs\n",
      "epoch=200/700 loss=1.5052, loss_layer=0.74714, loss_img=0.30225, loss_cyc=0.45581, epoch_duration=9 secs\n",
      "epoch=201/700 loss=1.5072, loss_layer=0.74715, loss_img=0.30234, loss_cyc=0.45771, epoch_duration=9 secs\n",
      "epoch=202/700 loss=1.50566, loss_layer=0.74712, loss_img=0.30233, loss_cyc=0.45621, epoch_duration=8 secs\n",
      "epoch=203/700 loss=1.50713, loss_layer=0.74717, loss_img=0.30238, loss_cyc=0.45758, epoch_duration=9 secs\n",
      "epoch=204/700 loss=1.50746, loss_layer=0.7471, loss_img=0.30232, loss_cyc=0.45805, epoch_duration=9 secs\n",
      "epoch=205/700 loss=1.5048, loss_layer=0.7469, loss_img=0.30225, loss_cyc=0.45566, epoch_duration=9 secs\n",
      "epoch=206/700 loss=1.50849, loss_layer=0.74714, loss_img=0.30237, loss_cyc=0.45898, epoch_duration=9 secs\n",
      "epoch=207/700 loss=1.50483, loss_layer=0.74687, loss_img=0.30227, loss_cyc=0.45568, epoch_duration=9 secs\n",
      "epoch=208/700 loss=1.50612, loss_layer=0.74692, loss_img=0.30232, loss_cyc=0.45688, epoch_duration=9 secs\n",
      "epoch=209/700 loss=1.50622, loss_layer=0.74694, loss_img=0.30228, loss_cyc=0.457, epoch_duration=9 secs\n",
      "epoch=210/700 loss=1.50751, loss_layer=0.747, loss_img=0.30238, loss_cyc=0.45813, epoch_duration=9 secs\n",
      "epoch=211/700 loss=1.50519, loss_layer=0.74675, loss_img=0.30222, loss_cyc=0.45622, epoch_duration=8 secs\n",
      "epoch=212/700 loss=1.50898, loss_layer=0.7471, loss_img=0.3024, loss_cyc=0.45948, epoch_duration=8 secs\n",
      "epoch=213/700 loss=1.50433, loss_layer=0.74671, loss_img=0.30223, loss_cyc=0.45539, epoch_duration=10 secs\n",
      "epoch=214/700 loss=1.50783, loss_layer=0.74688, loss_img=0.30241, loss_cyc=0.45854, epoch_duration=9 secs\n",
      "epoch=215/700 loss=1.50955, loss_layer=0.747, loss_img=0.30234, loss_cyc=0.46021, epoch_duration=8 secs\n",
      "epoch=216/700 loss=1.50493, loss_layer=0.74675, loss_img=0.30227, loss_cyc=0.45591, epoch_duration=8 secs\n",
      "epoch=217/700 loss=1.50584, loss_layer=0.74678, loss_img=0.30233, loss_cyc=0.45672, epoch_duration=8 secs\n",
      "epoch=218/700 loss=1.50879, loss_layer=0.74692, loss_img=0.30231, loss_cyc=0.45956, epoch_duration=8 secs\n",
      "epoch=219/700 loss=1.50706, loss_layer=0.74689, loss_img=0.30235, loss_cyc=0.45781, epoch_duration=8 secs\n",
      "epoch=220/700 loss=1.50739, loss_layer=0.74682, loss_img=0.30229, loss_cyc=0.45827, epoch_duration=8 secs\n",
      "epoch=221/700 loss=1.50401, loss_layer=0.74667, loss_img=0.30225, loss_cyc=0.45509, epoch_duration=9 secs\n",
      "new best loss=1.5040079022267225\n",
      "epoch=222/700 loss=1.50789, loss_layer=0.7468, loss_img=0.30229, loss_cyc=0.4588, epoch_duration=9 secs\n",
      "epoch=223/700 loss=1.50704, loss_layer=0.74674, loss_img=0.30228, loss_cyc=0.45803, epoch_duration=9 secs\n",
      "epoch=224/700 loss=1.50528, loss_layer=0.7467, loss_img=0.30231, loss_cyc=0.45627, epoch_duration=9 secs\n",
      "epoch=225/700 loss=1.50799, loss_layer=0.74682, loss_img=0.30228, loss_cyc=0.45889, epoch_duration=9 secs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36170/359600907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mstime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss_cyc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtrain_inv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALPHA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36170/4247441852.py\u001b[0m in \u001b[0;36mtrain_inv\u001b[0;34m(model, inv_model, device, data_loader, optimizer, epoch, alpha)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_loss_cyc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# torch.Size([128, 784]) torch.Size([128])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'std evaluated to zero after conversion to {}, leading to division by zero.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def round_(n, d=5):\n",
    "    return np.round(n, d)\n",
    "\n",
    "run_id = 'lr_1e-2'\n",
    "change_desc = 'larger LR 1e-2'\n",
    "is_resume = True\n",
    "run_path = OUTPUT_PATH/'runs'/run_id\n",
    "run_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EPOCHS = config_dict['epochs']\n",
    "ALPHA = config_dict['alpha']\n",
    "start_epoch = 0\n",
    "prev_best_loss = 999999\n",
    "total_training_time = 0\n",
    "\n",
    "state_path = run_path/'final_state_small_inv_nn.pt'\n",
    "\n",
    "if is_resume and state_path.exists():\n",
    "    state = torch.load(state_path)\n",
    "    inv_model.load_state_dict(state['model_state'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    start_epoch = state['epoch']+1\n",
    "    prev_best_loss = state['prev_best_loss']\n",
    "    print(f'resuming training for {run_id} from epoch {start_epoch}, last loss {state[\"loss\"]} prev_best_loss {prev_best_loss}')\n",
    "    \n",
    "\n",
    "wandb.init(project='nn-are-reversible',\n",
    "           entity='nayash', save_code=True, id=run_id,\n",
    "           name=run_id, notes=change_desc,\n",
    "           dir=run_path,\n",
    "           resume='allow',\n",
    "           config=config_dict)\n",
    "wandb.watch(inv_model)\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    stime = time.time()\n",
    "    total_loss, total_loss_layer, total_loss_img, total_loss_cyc = \\\n",
    "        train_inv(model, inv_model, device, inv_data_loader, optimizer, epoch, ALPHA)\n",
    "\n",
    "    epoch_time = time.time() - stime\n",
    "    total_training_time += epoch_time\n",
    "\n",
    "    print(f'epoch={epoch}/{EPOCHS} loss={round_(total_loss)}, loss_layer={round_(total_loss_layer)}, loss_img={round_(total_loss_img)}, loss_cyc={round_(total_loss_cyc)}, epoch_duration={round(epoch_time)} secs')\n",
    "    \n",
    "    wandb.log({\n",
    "        'loss':total_loss,\n",
    "        'loss_layer':total_loss_layer,\n",
    "        'loss_img':total_loss_img,\n",
    "        'loss_cyc':total_loss_cyc\n",
    "    })\n",
    "\n",
    "    if total_loss < prev_best_loss:\n",
    "        prev_best_loss = total_loss\n",
    "        state = {\n",
    "            'model_state': inv_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': prev_best_loss\n",
    "        }\n",
    "        torch.save(state, run_path/'state_small_inv_nn.pt')\n",
    "        print(f'new best loss={total_loss}')\n",
    "\n",
    "        \n",
    "state = {\n",
    "    'model_state': inv_model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': total_loss,\n",
    "    'prev_best_loss': prev_best_loss\n",
    "    }\n",
    "torch.save(state, state_path)\n",
    "        \n",
    "print(f'{EPOCHS} finished in {total_training_time/60} mins')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 51341<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>../outputs/runs/lr_1e-2/wandb/run-20211024_004119-lr_1e-2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>../outputs/runs/lr_1e-2/wandb/run-20211024_004119-lr_1e-2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>1.50799</td></tr><tr><td>loss_layer</td><td>0.74682</td></tr><tr><td>loss_img</td><td>0.30228</td></tr><tr><td>loss_cyc</td><td>0.45889</td></tr><tr><td>_runtime</td><td>1951</td></tr><tr><td>_timestamp</td><td>1635018222</td></tr><tr><td>_step</td><td>226</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>▆▅▄█▆▅▆▅▇▄▆▅▅▅▆▄▅▅▅▅▅▅▃▂▄▃▃▂▃▄▂▄▁▂▃▃▁▁▃▃</td></tr><tr><td>loss_layer</td><td>██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▅▄▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_img</td><td>██▇▇▇▇▆▆▇▆▆▆▅▆▆▅▅▅▅▅▅▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▁▁▂▁</td></tr><tr><td>loss_cyc</td><td>▅▃▂█▄▄▅▄█▃▅▅▅▅▆▃▄▅▆▅▅▅▄▂▅▂▄▂▄▅▃▅▁▁▄▄▂▁▄▅</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lr_1e-2</strong>: <a href=\"https://wandb.ai/nayash/nn-are-reversible/runs/lr_1e-2\" target=\"_blank\">https://wandb.ai/nayash/nn-are-reversible/runs/lr_1e-2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = {\n",
    "    'model_state': inv_model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': total_loss\n",
    "    }\n",
    "torch.save(state, state_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = torch.load(run_path/'final_state_small_inv_nn.pt')\n",
    "inv_model.load_state_dict(state['model_state'])\n",
    "\n",
    "inp = torch.tensor([0.9, 0, 0, 0, 0, 0, 0, 0, 0., 0.]).to(device)\n",
    "o = inv_model(inp)\n",
    "img = o.reshape((28, 28)).cpu().detach().numpy()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
