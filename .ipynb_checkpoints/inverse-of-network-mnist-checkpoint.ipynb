{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom collections import OrderedDict\nimport torch.nn.functional as F\n\ntorch.manual_seed(999)\n\nclass Net(nn.Module):\n    def __init__(self, input_size, out_size):\n        super(Net, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_size, 500),\n            nn.ReLU(),\n#             nn.Linear(1000, 500),\n#             nn.ReLU(),\n#             nn.Linear(500, 250),\n#             nn.ReLU(),\n#             nn.Linear(250, 125),\n#             nn.ReLU(),\n#             nn.Linear(125, 64),\n#             nn.ReLU(),\n#             nn.Linear(64, 32),\n#             nn.ReLU(),\n            nn.Linear(500, out_size)\n        )\n        \n    def forward(self, x):\n        return self.net(x)\n    \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbatch_size = 128\ntrain_kwargs = {'batch_size': batch_size,\n               'shuffle': True}\ntest_kwargs = {'batch_size': batch_size,\n              'shuffle': True}\nif device.type == 'cuda':\n    cuda_kwargs = {'num_workers': 1,\n                   'pin_memory': True,\n                   'shuffle': True}\n    train_kwargs.update(cuda_kwargs)\n    test_kwargs.update(cuda_kwargs)\ntransform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n        ])\ndataset1 = datasets.MNIST('../data', train=True, download=True,\n                   transform=transform)\ndataset2 = datasets.MNIST('../data', train=False,\n                   transform=transform)\ntrain_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\ntest_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n\nmodel = Net(28*28, 10).to(device)\noptimizer = optim.Adadelta(model.parameters(), lr=1e-2)\n            \nmodel","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:54:13.830671Z","iopub.execute_input":"2021-10-22T14:54:13.831381Z","iopub.status.idle":"2021-10-22T14:54:13.898831Z","shell.execute_reply.started":"2021-10-22T14:54:13.831348Z","shell.execute_reply":"2021-10-22T14:54:13.897772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loader)*batch_size","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:54:17.064964Z","iopub.execute_input":"2021-10-22T14:54:17.065294Z","iopub.status.idle":"2021-10-22T14:54:17.073425Z","shell.execute_reply.started":"2021-10-22T14:54:17.065262Z","shell.execute_reply":"2021-10-22T14:54:17.072153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nexamples = iter(test_loader)\nexample_data, example_targets = examples.next()\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(example_data[i][0], cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:54:18.91011Z","iopub.execute_input":"2021-10-22T14:54:18.910688Z","iopub.status.idle":"2021-10-22T14:54:19.741694Z","shell.execute_reply.started":"2021-10-22T14:54:18.910653Z","shell.execute_reply":"2021-10-22T14:54:19.74064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\n\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        # print(data.size(), data.view(data.size(0), -1).size())\n        optimizer.zero_grad()\n        output = model(data.view(data.size(0), -1))\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n\ndef test():\n    with torch.no_grad():\n        n_correct = 0\n        n_samples = 0\n        for images, labels in test_loader:\n            images = images.reshape(-1, 28*28).to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            # max returns (value ,index)\n            _, predicted = torch.max(outputs.data, 1)\n            n_samples += labels.size(0)\n            n_correct += (predicted == labels).sum().item()\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n    return acc\n\n\nbest_acc = -1\nbest_model = None\nfor epoch in range(1, 20):\n    train(model, device, train_loader, optimizer, epoch)\n    acc = test()\n    if acc > best_acc:\n        best_acc = acc\n        best_model = copy.deepcopy(model)\n        print(f'new best acc={best_acc}')\n    else:\n        print(f'current acc={acc}, prev_best_acc={best_acc}')","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:55:03.705439Z","iopub.execute_input":"2021-10-22T14:55:03.705859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:42:19.632844Z","iopub.execute_input":"2021-10-22T14:42:19.633682Z","iopub.status.idle":"2021-10-22T14:42:22.781885Z","shell.execute_reply.started":"2021-10-22T14:42:19.63363Z","shell.execute_reply":"2021-10-22T14:42:22.780822Z"},"trusted":true},"execution_count":null,"outputs":[]}]}